{
  "question": "NEUCHIPS Inc CES 2024 product highlight and specification",
  "response": {
    "query": "NEUCHIPS Inc CES 2024 product highlight and specification",
    "follow_up_questions": null,
    "answer": null,
    "images": null,
    "results": [
      {
        "title": "CES 2024: Neuchips Demos Low-Power AI Upgrade for PCs - IEEE Spectrum",
        "url": "https://spectrum.ieee.org/neuchips-low-power-ai",
        "content": "Topics\nSections\nMore\nFor IEEE Members\nFor IEEE Members\nIEEE Spectrum\nFollow IEEE Spectrum\nSupport IEEE Spectrum\nEnjoy more free content and benefits by creating an account\nSaving articles to read later requires an IEEE Spectrum account\nThe Institute content is only available for members\nDownloading full PDF issues is exclusive for IEEE Members\nAccess to Spectrum's Digital Edition is exclusive for IEEE Members\n The Global Project to Make a General Robotic Brain\nX-rays Reveal a New Phase of Matter\nThis Rice University Professor Developed Cancer-Detection Technology\nRelated Stories\nCES 2024 Preview: A Tricorder, Magic Mirrors, and a Solar EV\nQ-Dot Display Ups the Screen Arms Race\u2014on the Dashboard\nNew Records for the Biggest and Smallest AI Computers Neuchips Demos Low-Power AI Upgrade For PCs\nNot the most powerful at the show, but 55 watts is plenty accessible\nNot the most powerful at the show, but 55 watts is plenty accessible\nRaptor Gen AI accelerator chip\nWhat if any desktop PC could become an AI inference beast with a single upgrade? Following topics is a feature exclusive for IEEE Members\nAdding your response to an article requires an IEEE Spectrum account\nCreate an account to access more content and features on IEEE Spectrum, including the ability to save articles to read later, download Spectrum Collections, and participate in conversations with readers and editors. It came to CES Unveiled 2024\u2014the media pregame show before the main event\u2014with a PCIe add-on card that can upgrade the AI capabilities of a typical desktop computer while adding just 55 watts to the PC\u2019s power budget.\n",
        "score": 0.97162,
        "raw_content": "Topics\nSections\nMore\nFor IEEE Members\nFor IEEE Members\nIEEE Spectrum\nFollow IEEE Spectrum\nSupport IEEE Spectrum\nEnjoy more free content and benefits by creating an account\nSaving articles to read later requires an IEEE Spectrum account\nThe Institute content is only available for members\nDownloading full PDF issues is exclusive for IEEE Members\nAccess to Spectrum's Digital Edition is exclusive for IEEE Members\nFollowing topics is a feature exclusive for IEEE Members\nAdding your response to an article requires an IEEE Spectrum account\nCreate an account to access more content and features on IEEE Spectrum, including the ability to save articles to read later, download Spectrum Collections, and participate in conversations with readers and editors. For more exclusive content and features, consider Joining IEEE.\nJoin the world\u2019s largest professional organization devoted to engineering and applied sciences and get access to all of Spectrum\u2019s articles, archives, PDF downloads, and other benefits. Learn more \u2192\nAccess Thousands of Articles \u2014 Completely Free\nCreate an account and get exclusive content and features: Save articles, download collections, and\ntalk to tech insiders \u2014 all free! For full access and benefits,\njoin IEEE as a paying member.\nCES 2024: Neuchips Demos Low-Power AI Upgrade For PCs\nNot the most powerful at the show, but 55 watts is plenty accessible\nNot the most powerful at the show, but 55 watts is plenty accessible\nRaptor Gen AI accelerator chip\nWhat if any desktop PC could become an AI inference beast with a single upgrade? And what if that transformed beast still sipped power like it was enjoying a martini?\nThat\u2019s the idea pitched by Neuchips, a Taiwanese startup founded in 2019 and known for delivering top-class AI efficiency. It came to CES Unveiled 2024\u2014the media pregame show before the main event\u2014with a PCIe add-on card that can upgrade the AI capabilities of a typical desktop computer while adding just 55 watts to the PC\u2019s power budget.\nIt\u2019s not just a concept. The card was plugged into a desktop computer on the show floor and offered real-time, off-line conversation with a chatbot powered by Meta\u2019s popular Llama 2 7B large language model (Neuchips says the card will also run Llama 2 13B).\nNeuchips\u2019 card, the Evo PCIe accelerator, is built around the company\u2019s Raptor Gen AI accelerator chip. The Raptor chip delivers \u201cup to 200 tera operations (TOPS) per second,\u201d and the company says it\u2019s optimized for transformer-based models.\nThe card Neuchips demonstrated had the Raptor chip, but a single chip isn\u2019t the card\u2019s final form. Neuchips\u2019 CEO Ken Lau, an Intel veteran of 26 years, says Raptor can be used to design cards with varying numbers of chips on-board.\n\u201cThe chip is actually scalable,\u201d says Lau. \u201cSo we start with one chip. And then we have four chips. And then eight chips.\u201d Each chip provides up to 200 trillion operations per second (TOPS), according to Neuchip\u2019s press release. The card also carries 32GB of LPDDR5 memory, and reaches 1.6 terabytes of memory bandwidth. Memory bandwidth is important, because it\u2019s often often a factor when handling AI inference on a single PC.\nNeuchips wants to give owners the tools needed to use the card effectively as well, though with many months until release, the details here remain a bit sparse. A Neuchips representative said the company has compiler software and will provide a driver. The demonstration I saw had a custom interface for interacting with the Llama2-7B model Neuchips\u2019 card was running, but it appeared barebones.\nA focus on efficiency\nThere\u2019s already hardware that anyone can plug into a desktop\u2019s PCie slot to greatly improve AI performance. It\u2019s called a GPU, and Nvidia has a stranglehold on the market. Going toe-to-toe with Nvidia on performance would be difficult. In fact, Nvidia announced new cards with a focus on AI at CES 2024; the RTX 4080 Super, which will retail for US $999 starting on 31 January, quotes AI performance of up to 836 TOPs.\nNeuchips, however, sees an opening. \u201cWe are focused on power efficiency,\u201d says Lau. \u201cAnd on handling the many different models that are out there.\u201d\nModern graphics cards are powerful, but also power-hungry. The RTX 4080 Super can draw up to 320 watts of power and will typically require a computer with a power supply that can deliver at least 750 watts. Neuchips\u2019 Evo PCIe accelerator, by contrast, consumes just 55 watts of power. It consumes so little power, in fact, that the card Neuchips demonstrated at CES didn\u2019t have an external PCIe power connection. Such connectors are a must for most GPU cards.\nI was also told the final card, which should ship in the latter half of 2024, will be roughly half the size of the card shown at CES. That\u2019s an important detail, as the card I saw was as large as most current Nvidia GPU cards, and too large to fit most small form-factor desktop computers. A smaller card would make the Evo PCIe accelerator usable in a wide range of modern PC hardware.\nNeuchips\u2019 accelerator, though perhaps the most high-profile AI accelerator card at CES 2024, was far from alone at the show. Several start-ups came with their own AI accelerators packing unique features. Panmnesia won a CES Innovation Award for an AI accelerator which includes a Compute eXpress Link interface for access to huge pools of memory. Other companies with AI accelerators include DeepX and MemryX. Intel and AMD are in on it, too; each offers an AI accelerator in its latest CPU architecture.\nMake no mistake. Nvidia remains the 800-pound gorilla in this arena, and that\u2019s not going to change overnight. Still, new AI accelerators like Neuchips\u2019 Raptor and the Evo PCIe card look ready to deliver new options for developers who don\u2019t care about graphics or have a need for improved power efficiency while running AI inference.\nNeuchips\u2019 Evo PCI accelerator is due for full release in the second half of 2024. Pricing remains to be announced.\nMatthew S. Smith is a freelance consumer-tech journalist. An avid gamer, he is a former staff editor at Digital Trends and is particularly fond of wearables, e-bikes, all things smartphone, and CES, which he has attended every year since 2009.\nThe Global Project to Make a General Robotic Brain\nX-rays Reveal a New Phase of Matter\nThis Rice University Professor Developed Cancer-Detection Technology\nRelated Stories\nCES 2024 Preview: A Tricorder, Magic Mirrors, and a Solar EV\nQ-Dot Display Ups the Screen Arms Race\u2014on the Dashboard\nNew Records for the Biggest and Smallest AI Computers"
      },
      {
        "title": "Neuchips to Showcase Industry-Leading Gen AI Inferencing Accelerators ...",
        "url": "https://neuchips.ai/en/news/article/711ZY14mZahw7StF",
        "content": "Neuchips to Showcase Industry-Leading Gen AI Inferencing Accelerators at CES 2024. ... PRODUCT OVERVIEW By providing hardware Artificial Intelligence Engine ... San Jose, January 2 th, 2024. Neuchips ...",
        "score": 0.95966,
        "raw_content": "Neuchips to Showcase Industry-Leading Gen AI Inferencing Accelerators at CES 2024\nSan Jose, January 2th, 2024\nNeuchips, a leading AI Application-Specific Integrated Circuits (ASIC) solutions provider, will demo its revolutionary Raptor Gen AI accelerator chip (previously named N3000) and Evo PCIe accelerator card LLM solutions at CES 2024. Raptor, the new chip solution, enables enterprises to deploy large language models (LLMs) inference at a fraction of the cost of existing solutions.\n\"We are thrilled to unveil our Raptor chip and Evo card to the industry at CES 2024,\" said Ken Lau, CEO of Neuchips. \"Neuchips\u2019 solutions represent a massive leap in price to performance for natural language processing. With Neuchips, any organisation can now access the power of LLMs for a wide range of AI applications.\"\nDemocratising Access to LLMs\nTogether, Raptor and Evo provide an optimised stack that makes market-leading LLMs readily accessible for enterprises. Neuchips\u2019 AI solutions significantly reduce hardware costs compared to existing solutions. The high energy efficiency also minimizes electricity usage, further lowering the total cost of ownership.\nAt CES 2024, Neuchips will demo Raptor and Evo, accelerating the Whisper and Llama AI chatbots on a Personal AI Assistant application. This solution highlights the power of LLM inferencing for real business needs.\nEnterprises interested in test-driving Neuchips\u2019 breakthrough performance can visit booth 62700 to enrol in a free trial program. Additional technical sessions will showcase how Raptor and Evo can slash deployment costs for speech-to-text applications.\nRaptor Gen AI Accelerator Powers Breakthrough LLM Performance\nThe Raptor chip delivers up to 200 tera operations per second (TOPS) per chip. Its outstanding performance for AI inferencing operations such as Matrix Multiply, Vector, and embedding table lookup suits Gen-AI and transformer-based AI models. This groundbreaking throughput is achieved via Neuchips\u2019 patented compression and efficiency optimisations tailored to neural networks.\nEvo Gen 5 PCIe Card Sets New Standard for Acceleration and Low Power Consumption\nComplementing Raptor is Neuchips\u2019 ultra-low powered Evo acceleration card. Evo combines PCIe Gen 5 with eight lanes and LPDDR5 32GB to achieve 64GB/s host I/O bandwidth and 1.6-Tbps\u00a0of memory bandwidth at just 55 watts per card.\nAs demonstrated with DLRM, Evo also features 100% scalability, allowing customers to linearly increase performance by adding more chips. This modular design ensures investment protection for future AI workloads.\nAn upcoming half-height half-length (HHHL) form factor product, Viper, set to be launched by the second half of 2024, will provide even greater deployment flexibility. The new series brings data centre-class AI acceleration in a compact design.\nBooth Information\nDate: 9 \u2013 12 January 2024\nLocation: The Venetian Expo\nBooth Number: 62700\nGet the latest NEUCHIPS news by email.\n\u00a9NEUCHIPS Inc. All Rights Reserved.\nPrivacy Policy\nDesigned by MINMAX"
      },
      {
        "title": "Neuchips to Showcase Industry-Leading Gen AI Inferencing Accelerators ...",
        "url": "https://en.prnasia.com/releases/global/neuchips-to-showcase-industry-leading-gen-ai-inferencing-accelerators-at-ces-2024-432637.shtml",
        "content": "At CES 2024, Neuchips will demo Raptor and Evo, accelerating the Whisper and Llama AI chatbots on a Personal AI Assistant application. This solution highlights the power of LLM inferencing for real business needs. Enterprises interested in test-driving Neuchips' breakthrough performance can visit booth 62700 to enrol in a free trial program.",
        "score": 0.88301,
        "raw_content": "Neuchips to Showcase Industry-Leading Gen AI Inferencing Accelerators at CES 2024\nLAS VEGAS, Nev., Jan. 3, 2024 /PRNewswire/ --\u00a0Neuchips, a leading AI Application-Specific Integrated Circuits (ASIC) solutions provider, will demo its revolutionary Raptor Gen AI accelerator chip (previously named N3000) and Evo PCIe accelerator card LLM solutions at CES 2024. Raptor, the new chip solution, enables enterprises to deploy large language models (LLMs) inference at a fraction of the cost of existing solutions.\nRaptor Gen AI Accelerator Powers Breakthrough LLM Performance\n\"We are thrilled to unveil our Raptor chip and Evo card to the industry at CES 2024,\" said Ken Lau, CEO of Neuchips. \"Neuchips' solutions represent a massive leap in price to performance for natural language processing. With Neuchips, any organisation can now access the power of LLMs for a wide range of AI applications.\"\nDemocratising Access to LLMs\nTogether, Raptor and Evo provide an optimised stack that makes market-leading LLMs readily accessible for enterprises. Neuchips' AI solutions significantly reduce hardware costs compared to existing solutions. The high energy efficiency also minimizes electricity usage, further lowering the total cost of ownership.\nAt CES 2024, Neuchips will demo Raptor and Evo, accelerating the Whisper and Llama AI chatbots on a Personal AI Assistant application. This solution highlights the power of LLM inferencing for real business needs.\nEnterprises interested in test-driving Neuchips' breakthrough performance can visit booth 62700 to enrol in a free trial program. Additional technical sessions will showcase how Raptor and Evo can slash deployment costs for speech-to-text applications.\nRaptor Gen AI Accelerator Powers Breakthrough LLM Performance\nThe Raptor chip delivers up to 200 tera operations per second (TOPS) per chip. Its outstanding performance for AI inferencing operations such as Matrix Multiply, Vector, and embedding table lookup suits Gen-AI and transformer-based AI models. This groundbreaking throughput is achieved via Neuchips' patented compression and efficiency optimisations tailored to neural networks.\nEvo Gen 5 PCIe Card Sets New Standard for Acceleration and Low Power Consumption\nComplementing Raptor is Neuchips' ultra-low powered Evo acceleration card. Evo combines PCIe Gen 5 with eight lanes and LPDDR5 32GB to achieve 64GB/s host I/O bandwidth and 1.6-Tbps per second of memory bandwidth at just 55 watts per card.\nAs demonstrated with DLRM, Evo also features 100% scalability, allowing customers to linearly increase performance by adding more chips. This modular design ensures investment protection for future AI workloads.\nAn upcoming half-height half-length (HHHL) form factor product, Viper, set to be launched by the second half of 2024, will provide even greater deployment flexibility. The new series brings data centre-class AI acceleration in a compact design.\nMore information about Neuchips' involvement at CES 2024 can be found at www.neuchips.ai.\nBooth Information\u00a0 Date: 9 \u2013 12 January 2024Location: Westgate Las Vegas & Las Vegas Convention and World Trade Center (LVCC)Booth Number: 62700\nAbout Neuchips\nNeuchips is at the forefront of AI ASIC solutions, pioneering the development of purpose-built hardware for DLRM and LLM. With our dedicated team of experts, a commitment to innovation, and a strong presence in industry organizations, we are poised to continue shaping the future of AI hardware and ushering in a new era of efficiency and performance.\nEvo Gen 5 PCIe Card Sets New Standard for Acceleration and Low Power Consumption\nThe Choice of 400 Million Families -- Innovative Pioneer SKYWORTH Sets a New Standard in High-Tech Home Viewing\nViewSonic Sets New Horizons for Productive Workplace at ISE 2024\nCES 2024: EDINT's Mobile-based Proctoring Service \"Proctormatic\" Sets Stage for Global Expansion\nESR Announces the Launch of the World's First Qi2 Car Charger\nTHIRD MAN HARDWARE AND DONNER RELEASE THE TRIPLE THREAT\nBICSI Releases 15th Edition of TDMM for Cabling Design"
      },
      {
        "title": "Neuchips to Showcase Industry-Leading Gen AI Inferencing Accelerators ...",
        "url": "https://finance.yahoo.com/news/neuchips-showcase-industry-leading-gen-180000688.html",
        "content": "LAS VEGAS, Nev., Jan. 2, 2024 /PRNewswire/ -- Neuchips, a leading AI Application-Specific Integrated Circuits ( ASIC) solutions provider, will demo its revolutionary Raptor Gen AI accelerator...",
        "score": 0.87113,
        "raw_content": "S&P 500\nDow 30\nNasdaq\nRussell 2000\nCrude Oil\nGold\nSilver\nEUR/USD\n10-Yr Bond\nGBP/USD\nUSD/JPY\nBitcoin USD\nCMC Crypto 200\nFTSE 100\nNikkei 225\nNeuchips to Showcase Industry-Leading Gen AI Inferencing Accelerators at CES 2024\nLAS VEGAS, Nev., Jan. 2, 2024 /PRNewswire/ --\u00a0Neuchips, a leading AI Application-Specific Integrated Circuits (ASIC) solutions provider, will demo its revolutionary Raptor Gen AI accelerator chip (previously named N3000) and Evo PCIe accelerator card LLM solutions at CES 2024. Raptor, the new chip solution, enables enterprises to deploy large language models (LLMs) inference at a fraction of the cost of existing solutions.\n\"We are thrilled to unveil our Raptor chip and Evo card to the industry at CES 2024,\" said Ken Lau, CEO of Neuchips. \"Neuchips' solutions represent a massive leap in price to performance for natural language processing. With Neuchips, any organisation can now access the power of LLMs for a wide range of AI applications.\"\nDemocratising Access to LLMs\nTogether, Raptor and Evo provide an optimised stack that makes market-leading LLMs readily accessible for enterprises. Neuchips' AI solutions significantly reduce hardware costs compared to existing solutions. The high energy efficiency also minimizes electricity usage, further lowering the total cost of ownership.\nAt CES 2024, Neuchips will demo Raptor and Evo, accelerating the Whisper and Llama AI chatbots on a Personal AI Assistant application. This solution highlights the power of LLM inferencing for real business needs.\nEnterprises interested in test-driving Neuchips' breakthrough performance can visit booth 62700 to enrol in a free trial program. Additional technical sessions will showcase how Raptor and Evo can slash deployment costs for speech-to-text applications.\nRaptor Gen AI Accelerator Powers Breakthrough LLM Performance\nThe Raptor chip delivers up to 200 tera operations per second (TOPS) per chip. Its outstanding performance for AI inferencing operations such as Matrix Multiply, Vector, and embedding table lookup suits Gen-AI and transformer-based AI models. This groundbreaking throughput is achieved via Neuchips' patented compression and efficiency optimisations tailored to neural networks.\nEvo Gen 5 PCIe Card Sets New Standard for Acceleration and Low Power Consumption\nComplementing Raptor is Neuchips' ultra-low powered Evo acceleration card. Evo combines PCIe Gen 5 with eight lanes and LPDDR5 32GB to achieve 64GB/s host I/O bandwidth and 1.6-Tbps per second of memory bandwidth at just 55 watts per card.\nAs demonstrated with DLRM, Evo also features 100% scalability, allowing customers to linearly increase performance by adding more chips. This modular design ensures investment protection for future AI workloads.\nAn upcoming half-height half-length (HHHL) form factor product, Viper, set to be launched by the second half of 2024, will provide even greater deployment flexibility. The new series brings data centre-class AI acceleration in a compact design.\nMore information about Neuchips' involvement at CES 2024 can be found at www.neuchips.ai.\nBooth Information\u00a0 Date: 9 \u2013 12 January 2024Location: Westgate Las Vegas & Las Vegas Convention and World Trade Center (LVCC)Booth Number: 62700\nAbout Neuchips\nNeuchips is at the forefront of AI ASIC solutions, pioneering the development of purpose-built hardware for DLRM and LLM. With our dedicated team of experts, a commitment to innovation, and a strong presence in industry organizations, we are poised to continue shaping the future of AI hardware and ushering in a new era of efficiency and performance.\nView original content to download multimedia:https://www.prnewswire.com/news-releases/neuchips-to-showcase-industry-leading-gen-ai-inferencing-accelerators-at-ces-2024-302024412.html\nSOURCE Neuchips Inc.\nTRENDING"
      },
      {
        "title": "Neuchips is set to showcase Raptor Gen AI and Evo PCIe solutions at CES ...",
        "url": "https://multiplatform.ai/neuchips-is-set-to-showcase-raptor-gen-ai-and-evo-pcie-solutions-at-ces-2024/",
        "content": "At CES 2024, Neuchips will demonstrate the prowess of Raptor and Evo by accelerating the Whisper and Llama AI chatbots within a Personal AI Assistant application. This demonstration underscores the potential of LLM inferencing in addressing genuine business requirements. ... An upcoming product in the half-height half-length (HHHL) form factor ...",
        "score": 0.84903,
        "raw_content": "Optimizing Microscopic Image Analysis: Innovative Open-Source Software Advances AI Efficiency\nFAVA: A Game-Changer in Detecting and Correcting Language Model Hallucinations\nThe National Science Foundation partners with tech giants to launch the National Artificial Intelligence Research Resource pilot program\nUnlocking the Intricacies of RNA Transcription with Deep Learning\nNous-Hermes-2-Mixtral-8x7B: Transforming AI Content Generation and Understanding\nCEEZER Secures \u20ac10.3 Million in Funding for AI-Driven Carbon Credit Platform\nPublicis Unveils \u20ac300 Million AI Investment Strategy for Three Years\nDXwand Secures $4 Million Investment to Expand its Conversational AI Platform Across MENA Region\nEU lawmakers introduced measures to support AI startups and scale-ups in the generative AI field\nTorq Secures $42M in Series B Extension to Fuel Hyperautomation in Cybersecurity\nSK Hynix\u2019s Profit Revival Amidst AI Chip Demand Surge\nDusty Unveils Next-Gen Construction Layout Robot\nNorth Korea\u2019s Advancements in Artificial Intelligence Raise Alarms, Reveals Report\nEver.Ag Introduces AI-Powered Cheese Yield Enhancement\nBrazilian Researchers Harness AI to Combat Wildlife Roadway Fatalities\nEU lawmakers introduced measures to support AI startups and scale-ups in the generative AI field\nTorq Secures $42M in Series B Extension to Fuel Hyperautomation in Cybersecurity\nGoogle Unveils AI-Powered Educational Innovations at Bett Event\nUK Cybersecurity Agency Issues Warning: AI Enhances the Deception of Scam Emails\nMIT and Google Researchers Unveil Health-LLM: AI\u2019s New Frontier in Predictive Health with Wearable Sensors\nCEEZER Secures \u20ac10.3 Million in Funding for AI-Driven Carbon Credit Platform\nSouth African team backed by IDRC introduces AI-powered air-quality monitoring device\nAiDash Secures $50 Million in Funding for AI and Satellite-Powered Wildfire Risk Detection\nMetris Energy Secures \u00a32 Million Pre-Seed Funding for AI Solar Platform\nPrecision Livestock Technologies Unveils AI-Powered Cattle Feeding System\nNeuchips is set to showcase Raptor Gen AI and Evo PCIe solutions at CES 2024\nTL;DR:\nMain AI News:\nNeuchips, a renowned leader in AI Application-Specific Integrated Circuits (ASIC) solutions, is set to showcase its groundbreaking Raptor Gen AI accelerator chip (formerly known as N3000) and Evo PCIe accelerator card LLM solutions at CES 2024. The Raptor chip, a game-changing innovation, empowers enterprises to embrace large language models (LLMs) for inference tasks at a fraction of the cost of existing solutions.\nRaptor Gen AI Accelerator Redefines LLM Performance\nKen Lau, CEO of Neuchips, expressed his enthusiasm about the upcoming showcase, stating, \u201cWe are thrilled to introduce our Raptor chip and Evo card to the industry at CES 2024. Neuchips\u2019 solutions mark a monumental shift in the price-to-performance ratio for natural language processing. With Neuchips, organizations of all sizes can harness the capabilities of LLMs for a wide array of AI applications.\u201d\nDemocratizing Access to LLMs\nTogether, the Raptor chip and Evo card present a seamlessly optimized stack that democratizes access to market-leading LLMs for enterprises. Neuchips\u2019 AI solutions not only significantly reduce hardware costs compared to existing alternatives but also prioritize high energy efficiency, resulting in lower electricity consumption and an overall reduction in the total cost of ownership.\nAt CES 2024, Neuchips will demonstrate the prowess of Raptor and Evo by accelerating the Whisper and Llama AI chatbots within a Personal AI Assistant application. This demonstration underscores the potential of LLM inferencing in addressing genuine business requirements.\nEnterprises eager to experience Neuchips\u2019 breakthrough performance can visit booth 62700 to participate in a free trial program. In addition, technical sessions will shed light on how Raptor and Evo can drastically cut deployment costs for speech-to-text applications.\nRaptor Gen AI Accelerator: Paving the Way for Breakthrough LLM Performance\nThe Raptor chip boasts an astounding processing capability of up to 200 tera operations per second (TOPS) per chip. Its exceptional performance in AI inferencing operations, such as Matrix Multiply, Vector, and embedding table lookup, makes it ideally suited for Gen-AI and transformer-based AI models. This remarkable throughput is the result of Neuchips\u2019 patented compression techniques and efficiency optimizations finely tuned for neural networks.\nEvo Gen 5 PCIe Card Sets a New Benchmark for Acceleration and Energy Efficiency\nComplementing the Raptor chip is Neuchips\u2019 ultra-low-powered Evo acceleration card. Evo seamlessly combines PCIe Gen 5 with eight lanes and LPDDR5 32GB, delivering a staggering 64GB/s host I/O bandwidth and an impressive 1.6-Tbps per second of memory bandwidth, all while consuming just 55 watts per card.\nAs demonstrated with DLRM, Evo also offers 100% scalability, enabling customers to linearly increase performance by adding more chips. This modular design ensures that investments remain protected and future AI workloads can be efficiently accommodated.\nAn upcoming product in the half-height half-length (HHHL) form factor, Viper, is slated for launch in the latter half of 2024. This new series promises to provide even greater deployment flexibility, bringing data center-class AI acceleration in a compact and versatile design.\nConclusion:\nNeuchips\u2019 innovative Gen AI accelerators, Raptor and Evo, showcased at CES 2024, are poised to disrupt the market by providing cost-effective access to powerful AI inferencing capabilities. These solutions not only reduce hardware costs but also prioritize energy efficiency, making them an attractive proposition for businesses looking to leverage large language models in their AI applications. This development represents a significant advancement in the field and sets a new standard for AI acceleration, offering businesses a competitive edge in the market.\nSource\nSubscribe Now\nI have read and agree to the terms\nand conditions\nSubscribe\nSections\nConnect\nLegalese\nSubscribe Now\nI have read and agree to the terms\nand conditions\nSubscribe"
      },
      {
        "title": "Neuchips to showcase Gen AI Inferencing Accelerators at CES 2024",
        "url": "https://ai-techpark.com/neuchips-to-showcase-gen-ai-inferencing-accelerators-at-ces-2024/",
        "content": "Neuchips to showcase Gen AI Inferencing Accelerators at CES 2024\nNeuchips, a leading AI Application-Specific Integrated Circuits (ASIC) solutions provider, will demo its revolutionary\u00a0Raptor Gen AI accelerator chip\u00a0(previously named N3000) and\u00a0Evo\u00a0PCIe accelerator card\u00a0LLM solutions at\u00a0CES 2024. Evo combines PCIe Gen 5 with eight lanes and LPDDR5 32GB to achieve 64GB/s host I/O bandwidth and\u00a01.6-Tbps\u00a0per second of memory bandwidth at just 55 watts per card.\n POPULAR IN WEEK\nCareCloud strategically collaborates with Kovo HealthTech Corporation\nVeradigm Inc. announced the acquisition of Koha Health\nVisionet named a Major Player in Supply Chain...\n \u201cWe are thrilled to unveil our Raptor chip and Evo card to the industry at CES 2024,\u201d said\u00a0Ken Lau, CEO of Neuchips. Raptor, the new chip solution, enables enterprises to deploy large language models (LLMs) inference at a fraction of the cost of existing solutions.\n",
        "score": 0.82748,
        "raw_content": "Neuchips to showcase Gen AI Inferencing Accelerators at CES 2024\nNeuchips, a leading AI Application-Specific Integrated Circuits (ASIC) solutions provider, will demo its revolutionary\u00a0Raptor Gen AI accelerator chip\u00a0(previously named N3000) and\u00a0Evo\u00a0PCIe accelerator card\u00a0LLM solutions at\u00a0CES 2024. Raptor, the new chip solution, enables enterprises to deploy large language models (LLMs) inference at a fraction of the cost of existing solutions.\n\u201cWe are thrilled to unveil our Raptor chip and Evo card to the industry at CES 2024,\u201d said\u00a0Ken Lau, CEO of Neuchips. \u201cNeuchips\u2019 solutions represent a massive leap in price to performance for natural language processing. With Neuchips, any organisation can now access the power of LLMs for a wide range of AI applications.\u201d\nDemocratising Access to LLMs\nTogether, Raptor and Evo provide an optimised stack that makes market-leading LLMs readily accessible for enterprises. Neuchips\u2019 AI solutions significantly reduce hardware costs compared to existing solutions. The high energy efficiency also minimizes electricity usage, further lowering the total cost of ownership.\nAt CES 2024, Neuchips will demo Raptor and Evo, accelerating the Whisper and Llama AI chatbots on a Personal AI Assistant application. This solution highlights the power of LLM inferencing for real business needs.\nEnterprises interested in test-driving Neuchips\u2019 breakthrough performance can visit booth 62700 to enrol in a free trial program. Additional technical sessions will showcase how Raptor and Evo can slash deployment costs for\u00a0speech-to-text applications.\nRaptor Gen AI Accelerator Powers Breakthrough LLM Performance\nThe Raptor chip delivers up to 200 tera operations per second (TOPS) per chip. Its outstanding performance for AI inferencing operations such as Matrix Multiply, Vector, and embedding table lookup suits Gen-AI and transformer-based AI models. This groundbreaking throughput is achieved via Neuchips\u2019 patented compression and efficiency optimisations tailored to neural networks.\nEvo Gen 5 PCIe Card Sets New Standard for Acceleration and Low Power Consumption\nComplementing Raptor is Neuchips\u2019 ultra-low powered Evo acceleration card. Evo combines PCIe Gen 5 with eight lanes and LPDDR5 32GB to achieve 64GB/s host I/O bandwidth and\u00a01.6-Tbps\u00a0per second of memory bandwidth at just 55 watts per card.\nAs demonstrated with DLRM, Evo also features 100% scalability, allowing customers to linearly increase performance by adding more chips. This modular design ensures investment protection for future AI workloads.\nAn upcoming half-height half-length (HHHL) form factor product, Viper, set to be launched by the second half of 2024, will provide even greater deployment flexibility. The new series brings data centre-class AI acceleration in a compact design.\nMore information about Neuchips\u2019 involvement at CES 2024 can be found at\u00a0www.neuchips.ai.\nVisit AITechPark for cutting-edge Tech Trends around AI, ML, Cybersecurity, along with AITech News, and timely updates from industry professionals!\nPOPULAR IN WEEK\nCareCloud strategically collaborates with Kovo HealthTech Corporation\nVeradigm Inc. announced the acquisition of Koha Health\nVisionet named a Major Player in Supply Chain...\nVehere\u2019s AI Network Security Solution stole the show...\nAmenities Health available in the Panda Health Marketplace"
      },
      {
        "title": "Neuchips Unveiling Gen AI Inferencing Accelerators at CES 2024",
        "url": "https://pcge.eu/2024/01/neuchips-unveiling-cutting-edge-gen-ai-inferencing-accelerators-at-ces-2024/",
        "content": "Drawing exhibitors ranging from industry titans to startups across diverse sectors, including automotive, health and wellness, robotics, gaming, and artificial intelligence, CES transforms Las Vegas into a global tech hub, offering a glimpse into the future of technology through a wide array of showcases, from startup-focused Eureka Park to cutting-edge automotive and health tech exhibitions.\n Neuchips will showcase their\nRaptor Gen AI accelerator chip and Evo PCIe accelerator card LLM solutions at CES 2024, offering significant cost savings and improved performance for natural language processing applications.\n Neuchips, a leading provider of AI Application-Specific Integrated Circuits (ASIC) solutions, is set to showcase its\nRaptor Gen AI accelerator chip and Evo PCIe accelerator card LLM solutions at CES 2024. Additionally, Neuchips plans to launch Viper, a half-height half-length (HHHL) form factor product, in the second half of 2024, providing even greater deployment flexibility and bringing data center-class AI acceleration in a compact design.\n Related Posts\nTrending Posts\nEvergreen Posts\nLeave a Reply Cancel reply\nYou must be logged in to post a comment.\n",
        "score": 0.8154,
        "raw_content": "Neuchips Unveiling Gen AI Inferencing Accelerators at CES 2024\nJanuary 3, 2024\nSummary:\nNeuchips will showcase their\nRaptor Gen AI accelerator chip and Evo PCIe accelerator card LLM solutions at CES 2024, offering significant cost savings and improved performance for natural language processing applications.\nNeuchips, a leading provider of AI Application-Specific Integrated Circuits (ASIC) solutions, is set to showcase its\nRaptor Gen AI accelerator chip and Evo PCIe accelerator card LLM solutions at CES 2024. The Raptor chip, previously known as N3000, is a game-changer in the deployment of large language models (LLMs) inference, offering significant cost savings compared to existing solutions.\n\u201cWe are excited to introduce our Raptor chip and Evo card to the industry at CES 2024,\u201d said Ken Lau, CEO of Neuchips. \u201cNeuchips\u2019 solutions represent a major advancement in price to performance ratio for natural language processing. With Neuchips, organizations of all sizes can now leverage the power of LLMs for a wide range of AI applications.\u201d\nBy combining Raptor and Evo, Neuchips provides an optimized stack that makes leading LLMs easily accessible for enterprises. These AI solutions not only reduce hardware costs but also minimize electricity usage, resulting in lower total cost of ownership.\nAt CES 2024, Neuchips will demonstrate the capabilities of Raptor and Evo by accelerating the Whisper and Llama AI chatbots on a Personal AI Assistant application. This demonstration highlights the immense power of LLM inferencing for real business needs.\nEnterprises interested in experiencing Neuchips\u2019 breakthrough performance can visit booth 62700 to enroll in a free trial program. Furthermore, technical sessions will be conducted to showcase how Raptor and Evo can significantly reduce deployment costs for speech-to-text applications.\nThe Raptor chip is capable of delivering up to 200 tera operations per second (TOPS) per chip. Its exceptional performance in AI inferencing operations, such as Matrix Multiply, Vector, and embedding table lookup, makes it ideal for Gen-AI and transformer-based AI models. This remarkable throughput is achieved through Neuchips\u2019 patented compression and efficiency optimizations specifically designed for neural networks.\nComplementing the Raptor chip is Neuchips\u2019 Evo acceleration card, which boasts ultra-low power consumption. By combining PCIe Gen 5 with eight lanes and LPDDR5 32 GB, Evo achieves 64 GB/s host I/O bandwidth and 1.6-Tbps per second of memory bandwidth at just 55 watts per card.\nEvo also offers 100% scalability, allowing customers to increase performance linearly by adding more chips. This modular design ensures investment protection for future AI workloads. Additionally, Neuchips plans to launch Viper, a half-height half-length (HHHL) form factor product, in the second half of 2024, providing even greater deployment flexibility and bringing data center-class AI acceleration in a compact design.\n(Source)\nEvent Info\nAbout CES:\nCES, the Consumer Electronics Show, is an annual event held in Las Vegas, Nevada, organized by the Consumer Technology Association (CTA). With a history dating back to 1967, it has become the world's premier platform for unveiling and exploring the latest innovations in consumer electronics and technology. Drawing exhibitors ranging from industry titans to startups across diverse sectors, including automotive, health and wellness, robotics, gaming, and artificial intelligence, CES transforms Las Vegas into a global tech hub, offering a glimpse into the future of technology through a wide array of showcases, from startup-focused Eureka Park to cutting-edge automotive and health tech exhibitions.\nTechnology Explained\nLLM:\nA Large Language Model (LLM) is a highly advanced artificial intelligence system, often based on complex architectures like GPT-3.5, designed to comprehend and produce human-like text on a massive scale. LLMs possess exceptional capabilities in various natural language understanding and generation tasks, including answering questions, generating creative content, and delivering context-aware responses to textual inputs. These models undergo extensive training on vast datasets to grasp the nuances of language, making them invaluable tools for applications like chatbots, content generation, and language translation.\nLPDDR5:\nLPDDR5 is a type of computer memory technology that is used in many modern computers. It stands for Low Power Double Data Rate 5 and is the latest version of the LPDDR memory standard. It is a type of dynamic random access memory (DRAM) that is designed to be more power efficient than its predecessors. It is used in many modern laptops, tablets, and smartphones to provide faster performance and longer battery life. LPDDR5 is also used in some high-end gaming PCs and workstations to provide faster loading times and smoother gaming experiences. It is also used in some servers and data centers to provide faster data processing and storage.\nPCIe:\nPCIe (Peripheral Component Interconnect Express) is a high-speed serial computer expansion bus standard for connecting components such as graphics cards, sound cards, and network cards to a motherboard. It is the most widely used interface in the computer industry today, and is used in both desktop and laptop computers. PCIe is capable of providing up to 16 times the bandwidth of the older PCI standard, allowing for faster data transfer speeds and improved performance. It is also used in a variety of other applications, such as storage, networking, and communications. PCIe is an essential component of modern computing, and its applications are only expected to grow in the future.\nRelated Posts\nTrending Posts\nEvergreen Posts\nLeave a Reply Cancel reply\nYou must be logged in to post a comment.\nPopular Brands\nLatest Posts\nCategories\nPCGE Socials"
      },
      {
        "title": "NEUCHIPS",
        "url": "https://www.neuchips.ai/",
        "content": "NEUCHIPS\nNEUCHIPS Announces the Appointment of Ken Lau as Chief Executive Officer\nRecAccel\u2122 N3000 Delivers Industry Leading Results for MLPerf v3.0\u00a0DLRM Inference Benchmarking\nNEUCHIPS Secures $20 Million in Series B2 Funding\nOur Offering\nEvo Gen 5 PCIe Card\nDesigned for AI Inferencing\nNEUCHIPS is at the forefront of AI ASIC solutions, pioneering the development of purpose-built hardware for DLRM and LLM. Investors\nYoun-Long has 35 years of experience in IC design academy and industry, including co-founder, CTO & EVP at Global Unichip Corp., a TSMC subsidiary public company specialized in SOC design service; chair professor of computer science at National Tsing Hua University, Taiwan; co-founder of Taiwan\u2019s National Chip Implementation Center; Program director of the AI research Initiative sponsored by Taiwan\u2019s Ministry of Science and Technology, and an independent board member of Etron Technology. With our dedicated team of experts, a commitment to innovation, and a strong presence in industry organizations, we are poised to continue shaping the future of AI hardware and ushering in a new era of efficiency and performance.\n Taiwan-based Neuchips targets AI inference chip market with energy-efficient solutions\nNeuchips to Showcase Industry-Leading Gen AI Inferencing Accelerators at CES 2024\nRecAccel-World's 1st DLRM DSA solution\nExhibition |\nMeet Neuchips at SC23!\n At Intel,\nhe was responsible for forging the datacenter ecosystem between US and Asia and, most recently, leading Chromebook engineering with ODMs, OEMs, and key cloud service provider.\n",
        "score": 0.79845,
        "raw_content": "NEUCHIPS\nNEUCHIPS Announces the Appointment of Ken Lau as Chief Executive Officer\nRecAccel\u2122 N3000 Delivers Industry Leading Results for MLPerf v3.0\u00a0DLRM Inference Benchmarking\nNEUCHIPS Secures $20 Million in Series B2 Funding\nOur Offering\nEvo Gen 5 PCIe Card\nDesigned for AI Inferencing\nNEUCHIPS is at the forefront of AI ASIC solutions, pioneering the development of purpose-built hardware for DLRM and LLM. With our dedicated team of experts, a commitment to innovation, and a strong presence in industry organizations, we are poised to continue shaping the future of AI hardware and ushering in a new era of efficiency and performance.\nMedia\nStay up to date with the latest news and technology.\nTaiwan-based Neuchips targets AI inference chip market with energy-efficient solutions\nNeuchips to Showcase Industry-Leading Gen AI Inferencing Accelerators at CES 2024\nRecAccel-World's 1st DLRM DSA solution\nExhibition |\nMeet Neuchips at SC23!\nCareers\nJoin us to re-imagine deep learning recommendation system.\nContact Us\nTell us about your ideas and let us make ideas happen.\nLeadership\nPartners\nBringing AI possibilities to you with our partnership connection.\nInvestors\nYoun-Long has 35 years of experience in IC design academy and industry, including co-founder, CTO & EVP at Global Unichip Corp., a TSMC subsidiary public company specialized in SOC design service; chair professor of computer science at National Tsing Hua University, Taiwan; co-founder of Taiwan\u2019s National Chip Implementation Center; Program director of the AI research Initiative sponsored by Taiwan\u2019s Ministry of Science and Technology, and an independent board member of Etron Technology. He earned his PhD in computer science from the University of Illinois, Urbana-Champaign in 1987.\nFormer GM of Intel Taiwan with >26 years of ICT industry experience.\nAt Intel,\nhe was responsible for forging the datacenter ecosystem between US and Asia and, most recently, leading Chromebook engineering with ODMs, OEMs, and key cloud service provider.\nRobert has 30 years of experience in accounting and finance operations.\nHe\u2019s worked in both public and private sectors including 3 start-up companies. He was previously the CFO for Adi Capital Management LLC, a US investment company, and a key member of the launch team.\nPrior to Adi Capital, he was the CFO of Clairvoyance Capital Advisors LLC, an international investment company. He earned his BS in Management at Rensselaer Polytechnic Institute in 1991 and is a Certified Public Accountant in the State of New York. Robert enjoys spending time with his family and is actively involved in his local community.\nCL has 27 years of experience in IC design industry, including CTO, AMTC Corp., Program Manager, TSMC, Director at Global Unichip Corp., a TSMC subsidiary public company specialized in SOC design service.\nDr. Kao is CTO and the first employee of NEUCHIPS. He has established the Research and Development (R&D) team from its very inception and leads product roadmap and development. Dr. Kao earned his Ph.D. in computer science from National Tsing Hua University, Taiwan. He holds over 10 international patents in the areas of artificial intelligence, circuit design and image processing.\nGet the latest NEUCHIPS news by email.\n\u00a9NEUCHIPS Inc. All Rights Reserved.\nPrivacy Policy\nDesigned by MINMAX"
      },
      {
        "title": "Neuchips to Showcase Industry-Leading Gen AI ... - InvestorsObserver",
        "url": "https://www.investorsobserver.com/news/qm-pr/5109576210093573",
        "content": "LAS VEGAS, Nev. , Jan. 2, 2024 /PRNewswire/ -- Neuchips , a leading AI Application-Specific Integrated Circuits ( ASIC ) solutions provider, will demo its revolutionary Raptor Gen AI accelerator chip (previously named N3000) and Evo PCIe accelerator card LLM solutions at CES 2024 .",
        "score": 0.78627,
        "raw_content": "Neuchips to Showcase Industry-Leading Gen AI Inferencing Accelerators at CES 2024\nPR Newswire\nLAS VEGAS, Nev.\n,\nJan. 2, 2024\n/PRNewswire/ --\nNeuchips\n, a leading AI Application-Specific Integrated Circuits (\nASIC\n) solutions provider, will demo its revolutionary\nRaptor Gen AI accelerator chip\n(previously named N3000) and\nEvo\nPCIe accelerator card\nLLM solutions at\nCES 2024\n. Raptor, the new chip solution, enables enterprises to deploy large language models (LLMs) inference at a fraction of the cost of existing solutions.\n\"We are thrilled to unveil our Raptor chip and Evo card to the industry at CES 2024,\" said\nKen Lau\n, CEO of Neuchips. \"Neuchips' solutions represent a massive leap in price to performance for natural language processing. With Neuchips, any organisation can now access the power of LLMs for a wide range of AI applications.\"\nDemocratising Access to LLMs\nTogether, Raptor and Evo provide an optimised stack that makes market-leading LLMs readily accessible for enterprises. Neuchips' AI solutions significantly reduce hardware costs compared to existing solutions. The high energy efficiency also minimizes electricity usage, further lowering the total cost of ownership.\nAt CES 2024, Neuchips will demo Raptor and Evo, accelerating the Whisper and Llama AI chatbots on a Personal AI Assistant application. This solution highlights the power of LLM inferencing for real business needs.\nEnterprises interested in test-driving Neuchips' breakthrough performance can visit booth 62700 to enrol in a free trial program. Additional technical sessions will showcase how Raptor and Evo can slash deployment costs for\nspeech-to-text applications.\nRaptor Gen AI Accelerator Powers Breakthrough LLM Performance\nThe Raptor chip delivers up to 200 tera operations per second (TOPS) per chip. Its outstanding performance for AI inferencing operations such as Matrix Multiply, Vector, and embedding table lookup suits Gen-AI and transformer-based AI models. This groundbreaking throughput is achieved via Neuchips' patented compression and efficiency optimisations tailored to neural networks.\nEvo Gen 5 PCIe Card Sets New Standard for Acceleration and Low Power Consumption\nComplementing Raptor is Neuchips' ultra-low powered Evo acceleration card. Evo combines PCIe Gen 5 with eight lanes and LPDDR5 32GB to achieve 64GB/s host I/O bandwidth and\n1.6-Tbps\nper second of memory bandwidth at just 55 watts per card.\nAs demonstrated with DLRM, Evo also features 100% scalability, allowing customers to linearly increase performance by adding more chips. This modular design ensures investment protection for future AI workloads.\nAn upcoming half-height half-length (HHHL) form factor product, Viper, set to be launched by the second half of 2024, will provide even greater deployment flexibility. The new series brings data centre-class AI acceleration in a compact design.\nMore information about Neuchips' involvement at CES 2024 can be found at\nwww.neuchips.ai\n.\nBooth Information\nDate: 9 \u2013\n12 January 2024\nLocation: Westgate Las Vegas & Las Vegas Convention and World Trade Center (LVCC)\nBooth Number: 62700\nAbout Neuchips\nNeuchips is at the forefront of AI\nASIC\nsolutions, pioneering the development of purpose-built hardware for DLRM and LLM. With our dedicated team of experts, a commitment to innovation, and a strong presence in industry organizations, we are poised to continue shaping the future of AI hardware and ushering in a new era of efficiency and performance.\nView original content to download multimedia:\nhttps://www.prnewswire.com/news-releases/neuchips-to-showcase-industry-leading-gen-ai-inferencing-accelerators-at-ces-2024-302024412.html\nSOURCE\nNeuchips Inc.\nShare this article:\nSubscribe to our daily morning update newsletter and never miss out on the need-to-know market news, movements, and more.\nThank you for signing up! You're all set to receive the Morning Update newsletter\nRelated Articles\nHeritage Commerce Corp Earns $13.3 Million for the Fourth Quarter of 2023, and&#xA0;$64.4 Million for the Full Year 2023\nBOUNCEBACK ANNOUNCES K-12 PROFESSIONAL DEVELOPMENT PARTNERSHIP WITH EDUCATORS IN CLEVELAND, OHIO\nPIH Health One of the First in LA to Offer Persona IQ&#xAE;, the World's First and Only Smart Knee Implant for Total Knee Replacement Surgery\nDaiya and Lionel Boyce celebrate dupe culture with Fromage Forgery\nEcolomondo's Shares-For-Debt Agreement Approved By TSXV\nHYZON DELIVERS FIRST FOUR FUEL CELL ELECTRIC VEHICLES TO PERFORMANCE FOOD GROUP\nYou May Also Like\nRelated Articles\nHeritage Commerce Corp Earns $13.3 Million for the Fourth Quarter of 2023, and&#xA0;$64.4 Million for the Full Year 2023\nBOUNCEBACK ANNOUNCES K-12 PROFESSIONAL DEVELOPMENT PARTNERSHIP WITH EDUCATORS IN CLEVELAND, OHIO\nPIH Health One of the First in LA to Offer Persona IQ&#xAE;, the World's First and Only Smart Knee Implant for Total Knee Replacement Surgery\nDaiya and Lionel Boyce celebrate dupe culture with Fromage Forgery\nEcolomondo's Shares-For-Debt Agreement Approved By TSXV\nHYZON DELIVERS FIRST FOUR FUEL CELL ELECTRIC VEHICLES TO PERFORMANCE FOOD GROUP\nDownload the app\nStock Price data may be delayed up to 15 minutes.\nCopyright \u00a9 2024. Portions of this content may be copyrighted by Fresh Brewed Media, Investors Observer, and/or O2 Media LLC. All Rights Reserved. Portions of this content protected by US Patent numbers 7,865,496, 7,856,390, and 7,716,116. Investing in stocks, bonds, option and other financial instruments involve risks and may not be suitable for everyone. Portfolio results are unaudited and based on varying investment expiration dates. Terms of Service | Privacy Policy\nGet the InvestorsObserver App"
      },
      {
        "title": "Neuchips will show off its revolutionary Raptor Gen AI ... - TweakTown",
        "url": "https://www.tweaktown.com/news/95254/neuchips-will-show-off-its-revolutionary-raptor-gen-ai-accelerator-at-ces-2024/index.html",
        "content": "Neuchips will be demoing its new Raptor and Evo AI processors at CES 2024, accelerating the Whisper and Llama AI chatbots on a Personal AI Assistant application. Neuchips says it will be using its ...",
        "score": 0.75665,
        "raw_content": "Neuchips will show off its revolutionary Raptor Gen AI accelerator at CES 2024\nNeuchips is a leading AI ASIC provider, and is teasing its revolutionary Raptor Gen AI accelerator chip, previously known as N3000, at CES 2024.\nNeuchips will be unveiling its revolutionary new Raptor Gen AI accelerator and Evo PCIe accelerator card LLM products at CES 2024, according to a new press release issued by the company.\nNeuchips new Raptor Gen AI accelerator chip (source: Neuchips)\nThe upcoming Neuchips Raptor Gen AI accelerator was previously known as the N3000, with the new chip solution enabling enterprises to deploy large language models (LLMs) inference at a \"fraction of the cost\" of existing solutions. We will get the full skinny on Neuchips' new AI processor at CES 2024 next week.\nNeuchips CEO Ken Lau said in the press release: \"We are thrilled to unveil our Raptor chip and Evo card to the industry at CES 2024. Neuchips' solutions represent a massive leap in price to performance for natural language processing. With Neuchips, any organisation can now access the power of LLMs for a wide range of AI applications\".\nNeuchips will be demoing its new Raptor and Evo AI processors at CES 2024, accelerating the Whisper and Llama AI chatbots on a Personal AI Assistant application. Neuchips says it will be using its AI accelerators to show off the power of LLM inferencing for real business needs.\nNow, down to business. Neuchips' upcoming Raptor Gen AI chip has 200 tera operations per second (TOPS) per chip, with its outstanding performance for AI inferencing operations like Matrix Multiply, Vector, and embedding table lookup suits Gen AI and transformer-based AI models. Neuchips says that this new groundbreaking throughput is achieved through Neuchips' patented compression and efficiency optimizations that were tailor-made for neural networks.\nNeuchips' new Raptor AI processor will be joined by the ultra-low powered Evo acceleration card, which combines PCIe Gen5 with 8 lanes and 32GB of LPDDR5 memory which has 64GB/s host I/O bandwidth, and 1.6Tbps of memory bandwidth, all for just 55W per card. Very, very nice to see, Neuchips.\nEvo also features 100% scalability, which will allow customers to linearly increase performance by easily adding more chips. Neuchips points out that this modular design helps ensure customers' investment production for future AI workloads.\nNeuchips is also teasing its upcoming half-height, half-length (HHHL) form factor product, Viper, which will be launching in the second half of 2024. Viper will have \"even greater deployment flexibility,\" which the company says brings data center-class AI acceleration in a compact, small design.\nWe will see Neuchips' new Raptor Gen AI and Evo AI acceleration cards at CES 2024, so if you're there, the company says to drop by its booth (62700) to \"enroll in a free trial program'. Neuchips will have technical sessions that will showcase the power of its new Raptor and Evo products, where they can slash deployment costs for speech-to-text applications, and more.\nNVIDIA H100 80 GB Graphic Card PCIe HBM2e Memory 350W (NVIDIA H100 80 GB)\nAnthony Garreffa\nAnthony joined the TweakTown team in 2010 and has since reviewed 100s of graphics cards. Anthony is a long time PC enthusiast with a passion of hate for games built around consoles. FPS gaming since the pre-Quake days, where you were insulted if you used a mouse to aim, he has been addicted to gaming and hardware ever since. Working in IT retail for 10 years gave him great experience with custom-built PCs. His addiction to GPU tech is unwavering and has recently taken a keen interest in artificial intelligence (AI) hardware.\nWhat's in Anthony's PC?\nSimilar News\nRelated Tags\n\u00a9 1999-2024 Tweak Town Pty Ltd. All Rights Reserved. TweakTown\u00ae and its logo are registered trademarks."
      },
      {
        "title": "Neuchips to Showcase Industry-Leading Gen AI Inferencing ... - Morningstar",
        "url": "https://www.morningstar.com/news/pr-newswire/20240102hk02531/neuchips-to-showcase-industry-leading-gen-ai-inferencing-accelerators-at-ces-2024",
        "content": "LAS VEGAS, Nev., Jan. 2, 2024 /PRNewswire/ -- Neuchips, a leading AI Application-Specific Integrated Circuits (ASIC) solutions provider, will demo its revolutionary Raptor Gen AI accelerator...",
        "score": 0.73469,
        "raw_content": "Neuchips to Showcase Industry-Leading Gen AI Inferencing Accelerators at CES 2024\nNeuchips to Showcase Industry-Leading Gen AI Inferencing Accelerators at CES 2024\nPR Newswire\nLAS VEGAS, Nev., Jan. 2, 2024\nLAS VEGAS, Nev., Jan. 2, 2024 /PRNewswire/ --\u00a0Neuchips, a leading AI Application-Specific Integrated Circuits (ASIC) solutions provider, will demo its revolutionary Raptor Gen AI accelerator chip (previously named N3000) and Evo PCIe accelerator card LLM solutions at CES 2024. Raptor, the new chip solution, enables enterprises to deploy large language models (LLMs) inference at a fraction of the cost of existing solutions.\n\"We are thrilled to unveil our Raptor chip and Evo card to the industry at CES 2024,\" said Ken Lau, CEO of Neuchips. \"Neuchips' solutions represent a massive leap in price to performance for natural language processing. With Neuchips, any organisation can now access the power of LLMs for a wide range of AI applications.\"\nDemocratising Access to LLMs\nTogether, Raptor and Evo provide an optimised stack that makes market-leading LLMs readily accessible for enterprises. Neuchips' AI solutions significantly reduce hardware costs compared to existing solutions. The high energy efficiency also minimizes electricity usage, further lowering the total cost of ownership.\nAt CES 2024, Neuchips will demo Raptor and Evo, accelerating the Whisper and Llama AI chatbots on a Personal AI Assistant application. This solution highlights the power of LLM inferencing for real business needs.\nEnterprises interested in test-driving Neuchips' breakthrough performance can visit booth 62700 to enrol in a free trial program. Additional technical sessions will showcase how Raptor and Evo can slash deployment costs for speech-to-text applications.\nRaptor Gen AI Accelerator Powers Breakthrough LLM Performance\nThe Raptor chip delivers up to 200 tera operations per second (TOPS) per chip. Its outstanding performance for AI inferencing operations such as Matrix Multiply, Vector, and embedding table lookup suits Gen-AI and transformer-based AI models. This groundbreaking throughput is achieved via Neuchips' patented compression and efficiency optimisations tailored to neural networks.\nEvo Gen 5 PCIe Card Sets New Standard for Acceleration and Low Power Consumption\nComplementing Raptor is Neuchips' ultra-low powered Evo acceleration card. Evo combines PCIe Gen 5 with eight lanes and LPDDR5 32GB to achieve 64GB/s host I/O bandwidth and 1.6-Tbps per second of memory bandwidth at just 55 watts per card.\nAs demonstrated with DLRM, Evo also features 100% scalability, allowing customers to linearly increase performance by adding more chips. This modular design ensures investment protection for future AI workloads.\nAn upcoming half-height half-length (HHHL) form factor product, Viper, set to be launched by the second half of 2024, will provide even greater deployment flexibility. The new series brings data centre-class AI acceleration in a compact design.\nMore information about Neuchips' involvement at CES 2024 can be found at www.neuchips.ai.\nBooth Information\u00a0 Date: 9 \u2013 12 January 2024Location: Westgate Las Vegas & Las Vegas Convention and World Trade Center (LVCC)Booth Number: 62700\nAbout Neuchips\nNeuchips is at the forefront of AI ASIC solutions, pioneering the development of purpose-built hardware for DLRM and LLM. With our dedicated team of experts, a commitment to innovation, and a strong presence in industry organizations, we are poised to continue shaping the future of AI hardware and ushering in a new era of efficiency and performance.\nView original content to download multimedia:https://www.prnewswire.com/news-releases/neuchips-to-showcase-industry-leading-gen-ai-inferencing-accelerators-at-ces-2024-302024412.html\nSOURCE\nNeuchips Inc.\nMarket Updates\nStocks Hit Record Highs, Erasing Bear-Market Losses\nHas the Economy Already Landed?\n5 Cheap Value Stocks to Buy that Look Like Bargains\u2014For Now\nDo You Have the Wrong Index Funds for 2024\u2019s Stock Market?\nWhat\u2019s Happening In the Markets This Week\n2024 Outlook for the Stock Market and Economy\nWhy Fidelity\u2019s Denise Chisholm Is Optimistic About the Outlook for Stocks\n10 Reasons the Surprise Rally In Japanese Stocks Could Continue\nStock Picks\nCovered-Call Funds: A Mystery Wrapped Within an Enigma\nGoing Into Earnings, Is Apple Stock a Buy, a Sell, or Fairly Valued?\nServiceNow Earnings: Generative AI Contributes Meaningfully to Growth While Profitability Shines\nBest Energy Stocks to Buy\nTesla Earnings: Slower Growth Expected in 2024\nGoing Into Earnings, Is Alphabet Stock a Buy, a Sell, or Fairly Valued?\nAT&T Earnings: Modest Growth Should Offset Higher Taxes and Lower DirecTV Distributions In 2024\nUnited Airlines Earnings: Still Benefiting From Industry Capacity Constraints\nSponsor Center\nTransparency is how we protect the integrity of our work and keep\nempowering investors to achieve their goals and dreams. And we have\nunwavering standards for how we keep that integrity intact, from our\nresearch and data to our policies on content and your personal data.\nWe\u2019d like to share more about how we work and what drives our day-to-day business.\nHow we make money\nWe sell different types of products and services to both investment professionals\nand individual investors. These products and services are usually sold through\nlicense agreements or subscriptions. Our investment management business generates\nasset-based fees, which are calculated as a percentage of assets under management.\nWe also sell both admissions and sponsorship packages for our investment conferences\nand advertising on our websites and newsletters.\nHow we use your personal data\nHow we use your information depends on the product and service that you use and your relationship with us. We may use it to:\nTo learn more about how we handle and protect your data, visit our privacy center.\nHow we approach editorial content\nMaintaining independence and editorial freedom is essential to our mission of\nempowering investor success. We provide a platform for our authors to report on\ninvestments fairly, accurately, and from the investor\u2019s point of view. We also\nrespect individual opinions\u2013\u2013they represent the unvarnished thinking of our people\nand exacting analysis of our research processes. Our authors can publish views that\nwe may or may not agree with, but they show their work, distinguish facts from\nopinions, and make sure their analysis is clear and in no way misleading or deceptive.\nTo further protect the integrity of our editorial content, we keep a strict separation\nbetween our sales teams and authors to remove any pressure or influence on our analyses\nand research.\nRead our editorial policy to learn more about our process.\n\u00a9 Copyright 2024 Morningstar, Inc. All rights reserved.\nDow Jones Industrial Average, S&P 500, Nasdaq, and Morningstar Index (Market Barometer) quotes are real-time."
      }
    ],
    "response_time": 6.8
  }
}