{
  "Question": "Mobilint, Inc. CES 2024 product highlight and specification",
  "Summary": "Mobilint, Inc.\n\nCES 2024 Product Highlight:\n\n- ARIES: Edge NPU chip specialized for AI inference with up to 80 TOPS computing performance, efficient deep learning computing modules, and custom NPU compiler for high power-efficiency.\n\n- MLA100: High-performance PCIe AI accelerator for AI inference operations, scalable for applications requiring over 100 TOPS, suitable for smart factories, smart cities, autonomous robots, and on-premise servers.\n\n- MLX-A1: Stand-alone edge NPU-embedded AI box for high-performance AI inference in minimal space and power, supporting various communication interfaces such as MIPI, USB, and Ethernet.\n\n- User-friendly Mobilint SDK 'qb': Empowers developers to rapidly create AI applications for edge devices, ensuring effortless and efficient deployment process for AI models, maintaining over 99.9% accuracy, compatible with major ML frameworks, and supports over 100 AI models.\n\nMobilint offers world-leading AI chip solutions for edge and on-premise AI, providing a full-stack SDK and technical support."
}