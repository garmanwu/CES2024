{
    "Question": "Mobilint, Inc. CES 2024 product highlight and specification",
    "Summary": "Mobilint, Inc.\n\nCES 2024 Product Highlight:\n\n- ARIES: Edge NPU chip specialized for AI inference with up to 80 TOPS computing performance, efficient deep learning computing modules, and custom NPU compiler for high power-efficiency.\n\n- MLA100: High-performance PCIe AI accelerator for AI inference operations, scalable for applications requiring over 100 TOPS, suitable for smart factories, smart cities, autonomous robots, and on-premise servers.\n\n- MLX-A1: Stand-alone edge NPU-embedded AI box for high-performance AI inference in minimal space and power, supporting various communication interfaces such as MIPI, USB, and Ethernet.\n\n- User-friendly Mobilint SDK 'qb': Empowers developers to rapidly create AI applications for edge devices, ensuring effortless and efficient deployment process for AI models, maintaining over 99.9% accuracy, compatible with major ML frameworks, and supports over 100 AI models.\n\nMobilint offers world-leading AI chip solutions for edge and on-premise AI, providing a full-stack SDK and technical support.",
    "Summary_cn": "Mobilint公司。\n\nCES 2024产品亮点：\n\n- ARIES: 专为AI推理而设计的边缘NPU芯片，具备高达80 TOPS的计算性能，高效的深度学习计算模块以及高功率效率的定制NPU编译器。\n\n- MLA100: 高性能PCIe AI加速器，用于AI推理操作，可扩展至超过100 TOPS，适用于智能工厂、智能城市、自动机器人和服务器等应用场景。\n\n- MLX-A1: 独立的边缘NPU嵌入式AI盒子，占用空间和功耗极小，支持MIPI、USB和以太网等各种通信接口。\n\n- 用户友好的Mobilint SDK 'qb'：使开发人员能够快速创建适用于边缘设备的AI应用程序，确保AI模型的轻松高效部署，保持超过99.9%的准确度，与主要的机器学习框架兼容，并支持超过100个AI模型。\n\nMobilint提供全球领先的边缘和本地AI芯片解决方案，并提供全栈SDK和技术支持。"
}